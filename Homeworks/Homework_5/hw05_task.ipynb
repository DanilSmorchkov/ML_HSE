{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qp0H_zUQuu_"
   },
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10.\n",
    "\n",
    "Обратите внимание, что использование PyTorch во всех заданиях кроме последнего запрещено. Автоматической проверки на его использование не будет, однако все посылки будут проверены вручную. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "22ezVRf3QuvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from typing import List, NoReturn\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qfDPH_LQuvF"
   },
   "source": [
    "### Задание 1 (3 балла)\n",
    "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
    "\n",
    "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
    "\n",
    "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
    "\n",
    "\n",
    "#### Методы\n",
    "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
    "\n",
    "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
    "\n",
    "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения\n",
    "\n",
    "#### Оценка\n",
    "Валидируется корректность работы каждого модуля отдельно. Ожидается, что выходы каждого модуля будут незначительно отличаться от ожидаемых выходов, а подсчет градиента и градиентный спуск будут работать корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aYS2gE4PYepZ"
   },
   "outputs": [],
   "source": [
    "from task import ReLU, Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb_ip_h8QuvJ"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь сделаем саму нейронную сеть.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
    "\n",
    "`epochs` - количество эпох обучения\n",
    "\n",
    "`alpha` - скорость обучения\n",
    "\n",
    "#### Оценка\n",
    "Оценка производится на заданных ботом гиперпараметрах и архитектурах. Ожидается, что при подобранных заранее гиперпараметрах решение будет демонстрировать приемлемую точность.\n",
    "\n",
    "Всего 20 тестов по 500 точек в обучающей выборке и по 100 точек в тестовой выборке c 20 эпохами обучения и 10 тестов по 1000 точек в обучающей выборке и 200 точек в тестовой выборке с 40 эпохами обучения. Количество признаков варьируется от 2 до 8. Количество классов не более 8 и не менее 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q_JFCizKQuvK"
   },
   "outputs": [],
   "source": [
    "from task import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "onDymYQXQuvN"
   },
   "outputs": [],
   "source": [
    "p = MLPClassifier([\n",
    "    Linear(4, 8),\n",
    "    ReLU(),\n",
    "    Linear(8, 8),\n",
    "    ReLU(),\n",
    "    Linear(8, 2)\n",
    "])\n",
    "\n",
    "X = np.random.randn(50, 4)\n",
    "y = [(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X]\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C1EIsDqQuvQ"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
    "\n",
    "Первый датасет - датасет moons. В каждом тесте у данных всего два признака, классов также два.\n",
    "\n",
    "Второй датасет - датасет blobs. В каждом тесте у данных по два признака, классов три.\n",
    "\n",
    "\n",
    "Обратите внимание, что датасеты могут отличаться от приведенных ниже по количеству точек, уровню шума и положению центроидов. Количество классов и признаков остается неизменным.\n",
    "\n",
    "Обратите внимание, что классификатор будет обучаться ботом под каждый датасет отдельно. Обучать самостоятельно в файле `task.py` классификатор не нужно.\n",
    "\n",
    "Количество датасетов каждого типа равно 5. Количество точек в обучающей выборке не менее 1000, количество точек в тестовой выборке не менее 200.\n",
    "\n",
    "#### Оценка\n",
    "Средняя точность на датасетах moons больше 0.85 - +1 балл\n",
    "\n",
    "Средняя точность на датасетах blobs больше 0.85 - +1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import classifier_moons, classifier_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d5UAgXTcQuvQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons(1000, noise=0.075)\n",
    "X_test, y_test = make_moons(400, noise=0.075)\n",
    "classifier_moons.fit(X, y)\n",
    "print(\"Accuracy\", np.mean(classifier_moons.predict(X_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MMDJM4qFQuvT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(1000, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "classifier_blobs.fit(X, y)\n",
    "print(\"Accuracy\", np.mean(classifier_blobs.predict(X_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPbVTFnMQuvW"
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/) или обучать сеть на CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tV0mJLu-QuvX"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VUC_QqpAQuva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = transforms.ToTensor()\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
    "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGmpjcFfQuvd"
   },
   "source": [
    "### Задание 4 (3 балла)\n",
    "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
    "\n",
    "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
    "\n",
    "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
    "\n",
    "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5sRmTKwKQuve"
   },
   "outputs": [],
   "source": [
    "from task import TorchModel, calculate_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAsLmkUqQuvh"
   },
   "source": [
    "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k5G8iMCeQuvh"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.001)\n",
    "    train_losses = []\n",
    "    global best_params\n",
    "    test_losses = []\n",
    "    best_loss = None\n",
    "    for i in tqdm(range(epochs)):\n",
    "        #Train\n",
    "        model.train()\n",
    "        loss_mean = 0\n",
    "        elements = 0\n",
    "        for X, y in iter(train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        train_losses.append(loss_mean / elements)\n",
    "        #Test\n",
    "        model.eval()\n",
    "        loss_mean = 0\n",
    "        elements = 0\n",
    "        for X, y in iter(test_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        if best_loss is None or best_loss > loss_mean / elements:\n",
    "            best_loss = loss_mean / elements\n",
    "            best_params = copy.deepcopy(model.state_dict())\n",
    "        test_losses.append(loss_mean / elements)\n",
    "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
    "    print(f'best loss = {best_loss}', end=' ')\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmD9eWJOQuvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss 2.1330993451309204 | Test loss 2.002009179496765\n",
      "Epoch 1 | Train loss 1.9150422200775146 | Test loss 1.8243275915145873\n",
      "Epoch 2 | Train loss 1.763731887588501 | Test loss 1.7113450038909912\n",
      "Epoch 3 | Train loss 1.6666042484283448 | Test loss 1.6439187391281127\n",
      "Epoch 4 | Train loss 1.6008986407089234 | Test loss 1.5715576679229737\n",
      "Epoch 5 | Train loss 1.5557294578552245 | Test loss 1.5508306678771973\n",
      "Epoch 6 | Train loss 1.5120029695510864 | Test loss 1.4972027582168579\n",
      "Epoch 7 | Train loss 1.4884720426559448 | Test loss 1.4754192005157472\n",
      "Epoch 8 | Train loss 1.4599186771011352 | Test loss 1.457961282157898\n",
      "Epoch 9 | Train loss 1.4411220611190796 | Test loss 1.4317604524612426\n",
      "Epoch 10 | Train loss 1.4245860274124145 | Test loss 1.4839384309768677\n",
      "Epoch 11 | Train loss 1.408178265686035 | Test loss 1.4046225612640382\n",
      "Epoch 12 | Train loss 1.386587029800415 | Test loss 1.3868078536987305\n",
      "Epoch 13 | Train loss 1.365370013923645 | Test loss 1.3904732833862306\n",
      "Epoch 14 | Train loss 1.355398920097351 | Test loss 1.3619713861465454\n",
      "Epoch 15 | Train loss 1.3381058354187012 | Test loss 1.3684394403457643\n",
      "Epoch 16 | Train loss 1.323435839881897 | Test loss 1.3622695287704467\n",
      "Epoch 17 | Train loss 1.322818296585083 | Test loss 1.3308182327270508\n",
      "Epoch 18 | Train loss 1.293623044166565 | Test loss 1.3056912879943847\n",
      "Epoch 19 | Train loss 1.285463450164795 | Test loss 1.3284165990829468\n",
      "Epoch 20 | Train loss 1.2823522615432739 | Test loss 1.290611777496338\n",
      "Epoch 21 | Train loss 1.25337503200531 | Test loss 1.2805078329086304\n",
      "Epoch 22 | Train loss 1.2466732016372681 | Test loss 1.2610967443466186\n",
      "Epoch 23 | Train loss 1.23132634349823 | Test loss 1.259864754486084\n",
      "Epoch 24 | Train loss 1.2187950428009033 | Test loss 1.2436665214538574\n",
      "Epoch 25 | Train loss 1.2144328607940673 | Test loss 1.2363616010665894\n",
      "Epoch 26 | Train loss 1.1972810748672484 | Test loss 1.2299391061782836\n",
      "Epoch 27 | Train loss 1.1885000566864015 | Test loss 1.2281676387786866\n",
      "Epoch 28 | Train loss 1.1886708002471924 | Test loss 1.2267775983810425\n",
      "Epoch 29 | Train loss 1.1747430987548828 | Test loss 1.2195334327697753\n",
      "Epoch 30 | Train loss 1.1688212647628784 | Test loss 1.229044573020935\n",
      "Epoch 31 | Train loss 1.1565353072357178 | Test loss 1.2092508501052857\n",
      "Epoch 32 | Train loss 1.1445308329010009 | Test loss 1.2028580945968628\n",
      "Epoch 33 | Train loss 1.1395944033813477 | Test loss 1.2143975734710692\n",
      "Epoch 34 | Train loss 1.1370996069335937 | Test loss 1.1995417976379394\n",
      "Epoch 35 | Train loss 1.1237078749465943 | Test loss 1.2109906412124634\n",
      "Epoch 36 | Train loss 1.1203223350524902 | Test loss 1.175824251937866\n",
      "Epoch 37 | Train loss 1.1158874404525756 | Test loss 1.1675572854995728\n",
      "Epoch 38 | Train loss 1.1054479746246337 | Test loss 1.1708847303390504\n",
      "Epoch 39 | Train loss 1.0993798885345458 | Test loss 1.1721253135681153\n",
      "Epoch 40 | Train loss 1.1010716472244262 | Test loss 1.1689688930511475\n",
      "Epoch 41 | Train loss 1.0967886730194092 | Test loss 1.181579398727417\n",
      "Epoch 42 | Train loss 1.091034432220459 | Test loss 1.1776261489868165\n"
     ]
    }
   ],
   "source": [
    "model = TorchModel().to(device)\n",
    "train_l, test_l = train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJNAuHjNQuvn"
   },
   "source": [
    "Построим график функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6OEGqriQuvo"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
    "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miUxg0bDQuvs"
   },
   "source": [
    "И, наконец, посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXSOJFI8Quvt"
   },
   "outputs": [],
   "source": [
    "model = TorchModel().to(device)\n",
    "model.load_state_dict(best_params)\n",
    "model.eval()\n",
    "true_positive = np.zeros(10)\n",
    "true_negative = np.zeros(10)\n",
    "false_positive = np.zeros(10)\n",
    "false_negative = np.zeros(10)\n",
    "accuracy = 0\n",
    "ctn = 0\n",
    "for X, y in iter(test_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X).max(dim=1)[1]\n",
    "    for i in range(10):\n",
    "        for pred, real in zip(y_pred, y):\n",
    "            if real == i:\n",
    "                if pred == real:\n",
    "                    true_positive[i] += 1\n",
    "                else:\n",
    "                    false_negative[i] += 1\n",
    "            else:\n",
    "                if pred == i:\n",
    "                    false_positive[i] += 1\n",
    "                else:\n",
    "                    true_negative[i] += 1\n",
    "\n",
    "    accuracy += torch.sum(y_pred == y).item()\n",
    "    ctn += len(y)\n",
    "print(\"Overall accuracy\", accuracy / ctn)\n",
    "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
    "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
    "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
    "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKA-j4rIQuvv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw06_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
